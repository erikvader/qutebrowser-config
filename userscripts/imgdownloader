#!/bin/python

from bs4 import BeautifulSoup
import os
from urllib.parse import urlparse, unquote, parse_qs, urlunparse, quote
from urllib.request import urlopen, Request
from shutil import copyfileobj
from quteprinter import qute_print, qute_wprint

DOWNLOAD_DIR = os.environ["HOME"] + "/Downloads"

def gelbooruExtractor(soup):
    for a in soup.find_all("a"):
        if a.string == "Original image":
            return [a.get("href")]
    return []

def sankakucomplexExtractor(soup):
    # TODO: search for id directly instead
    for a in soup.find_all("a"):
        if a.get("id") == "highres":
            return [a.get("href")]
    return []

def chounyuuExtractor(soup):
    for i in soup.find_all("img"):
        # TODO: check if parent exists before accesing stuff from it
        if i.parent.name == "a" and i.parent.parent["class"] == ["image_box_image"]:
            return [i.get("src")]
    return []

def xfantazyExtractor(soup):
    # TODO: search for id directly instead
    for v in soup.find_all("video"):
        if v.get("id") == "fluid-videoplayer":
            return [v.get("src")]
    return []

def musesExtractor(soup):
    links = []
    for i in soup.find_all("img"):
        if i.get("class") == ["lazyloaded"]:
            # TODO: check if parent exists before accesing stuff from it
            filename = quote(i.parent.parent.get("title"))
            img = os.path.basename(i.get("src"))
            _, ext = os.path.splitext(img)
            links.append("/image/fm/{}?name={}{}".format(img, filename, ext))
    return links

def name_from_url(url):
    up = urlparse(url)
    params = parse_qs(up.query)

    for n in ["name"]:
        if n in params:
            return unquote(params[n][0])

    return os.path.basename(unquote(up.path))

def make_url_absolute(host, url):
    u = urlparse(url)
    return urlunparse((
        u.scheme if u.scheme else "https",
        u.netloc if u.netloc else host,
        u.path,
        u.params,
        u.query,
        u.fragment
    ))

def main():
    extractors = {
        "gelbooru.com": gelbooruExtractor,
        "chan.sankakucomplex.com": sankakucomplexExtractor,
        "g.chounyuu.com": chounyuuExtractor,
        "xfantazy.com": xfantazyExtractor,
        "comics.8muses.com": musesExtractor,
    }

    if "QUTE_HTML" not in os.environ:
        print("must be run from qutebrowser")
        exit(1)

    host = urlparse(os.environ["QUTE_URL"]).hostname

    extractor = extractors.get(host, None)

    if extractor is None:
        qute_wprint("site not supported")
        return

    with open(os.environ["QUTE_HTML"], "r") as fp:
        soup = BeautifulSoup(fp, "html5lib")

    image_urls = extractor(soup)

    if not image_urls:
        qute_wprint("didn't extract any images")
        return

    qute_print("Downloading...")
    for u in image_urls:
        full_url = make_url_absolute(host, u)
        filename = name_from_url(full_url)
        path = os.path.join(DOWNLOAD_DIR, filename)

        r = Request(full_url, headers={'User-Agent': 'Mozilla/5.0'})
        with urlopen(r) as uopen, open(path, "wb") as f:
            copyfileobj(uopen, f)
            qute_print("Downloaded " + filename + "!")
    qute_print("Done!")

if __name__ == "__main__":
   main()
