#!/bin/python

import os, sys, re, atexit
from bs4 import BeautifulSoup
from fcntl import flock, LOCK_EX
import pickle as P
import json
import tempfile
import subprocess as SP
from quteprinter import qute_print, qute_wprint, qute_eprint

runningFile = "/tmp/instaloot_running"
dest = os.path.join(os.environ["HOME"], "Pictures/instagram")
cacheFile = "/tmp/instaloot_cache"

gallery_dl_conf_data = {
   "extractor": {
      "base-directory": dest,
      "filename": "{username}.{date!s:.10}.{media_id}.{extension}",
      "directory": ["{username}"]
   }
}
gallery_dl_conf = "/tmp/gallery_dl_conf_instagram"

def safeWriteOpen(filepath, fun, initf, binary=False):
   try:
      with open(filepath, "xb+" if binary else "x+") as f:
         flock(f, LOCK_EX)
         initf(f)
         return fun(f)
   except FileExistsError:
      with open(filepath, "rb+" if binary else "r+") as f:
         flock(f, LOCK_EX)
         return fun(f)

def removeFromCache(codes):
   def doFile(f):
      toDump = P.load(f) - set(codes)
      f.seek(0)
      f.truncate(0)
      P.dump(toDump, f)
   def initFile(f):
      P.dump(set(), f)
      f.seek(0)
   safeWriteOpen(cacheFile, doFile, initFile, binary=True)

def testSetCache(codes):
   def doFile(f):
      cache = P.load(f)
      newones = [x for x in codes if x not in cache]
      if not newones:
         return newones
      else:
         cache.update(newones)
         f.seek(0)
         f.truncate(0)
         P.dump(cache, f)
         return newones
   def initFile(f):
      P.dump(set(), f)
      f.seek(0)
   return safeWriteOpen(cacheFile, doFile, initFile, binary=True)

def get_cookies(f):
   exe = os.path.join(os.environ["QUTE_CONFIG_DIR"], "userscripts", "print_cookies")
   cookies = os.path.join(os.environ["QUTE_DATA_DIR"], "webengine", "Cookies")
   SP.run([exe, cookies, ".instagram.com"], stdout=f, check=True)

def downloadPosts(urls):
   newones = testSetCache(urls)
   if not newones:
      qute_print("Already downloaded all {} links".format(len(urls)))
      return

   qute_print("Found {} links, I have seen {} before".format(len(urls), len(urls) - len(newones)))

   dups = 0
   succ = 0
   error = False

   with tempfile.NamedTemporaryFile(mode="w+") as input_file,\
        tempfile.NamedTemporaryFile(mode="w+") as conf_file,\
        tempfile.NamedTemporaryFile(mode="w+") as cookie_file:
      json.dump(gallery_dl_conf_data, conf_file)
      conf_file.flush()

      for url in newones:
         input_file.write(url)
         input_file.write('\n')
      input_file.flush()

      get_cookies(cookie_file)
      cookie_file.flush()

      proc = SP.Popen(
         [
            "gallery-dl",
            "--cookies", cookie_file.name,
            "--input-file", input_file.name,
            "--config", conf_file.name
         ],
         stdout=SP.PIPE,
         stderr=SP.PIPE,
         text=True)

      for line in proc.stdout:
         if line.startswith("# "):
            dups += 1
            qute_print(" dup: {}".format(line.rstrip()[2:]))
         elif line.startswith(dest):
            succ += 1
            qute_print("succ: {}".format(line.rstrip()))
         else:
            error = True
            qute_eprint("unexpected line from stdout: '{}'".format(line))

      for line in proc.stderr:
         if not re.match(r"^\[[0-9]+/[0-9]+\]", line) and line.rstrip() != "[instagram][warning] Cookie 'sessionid' will expire in less than 1 hour":
            error = True
            qute_eprint(line.rstrip())

      if error:
         removeFromCache(newones)

      proc.wait()

      qute_print("Downloaded {} new files and {} files already existed ({} links)".format(succ, dups, len(newones)))

def run_all():
   try:
      with open(runningFile, "x") as f:
         f.write(str(os.getpid()))
      atexit.register(lambda: os.remove(runningFile))
   except FileExistsError:
      qute_wprint("Another instance of this script is already running in all-mode")
      return

   with open(os.environ["QUTE_HTML"], "r") as fp:
      soup = BeautifulSoup(fp, "html5lib")

   hrefs = (h.get("href") for h in soup.find_all("a") if h)
   links = ["https://instagram.com" + l for l in hrefs if l and l.startswith("/p/")]

   if not links:
      qute_wprint("Found no valid links")
      return

   downloadPosts(links)

def run_current():
   url = os.environ["QUTE_URL"]
   mat = re.match(r"^(https://)?(www\.)?instagram\.com/p/(.+?)(/|$)", url)
   if not mat:
      qute_wprint("{} is an invalid link :(".format(url))
      return

   downloadPosts([url])

def main():
   display_usage = False

   if not "QUTE_HTML" in os.environ:
      print("is this really running in qutebrowser?")
      exit(1)

   args = {}
   argv = sys.argv[1:].copy()
   while argv:
      a = argv.pop(0)
      if a == "--current":
         args['current'] = True
      elif a == "--all":
         args['all'] = True
      else:
         display_usage = True
         break

   if "current" in args:
      run_current()
   elif "all" in args:
      run_all()
   else:
      display_usage = True

   if display_usage:
      qute_print("usage: instaloot --current | --all")
      exit(1)

if __name__ == "__main__":
   main()
